Machine learning is an ever-expanding field, with wide-reaching applications in areas such as economics, biology, and medicine, just to name a few. With such a wide variety of use cases comes a wide range of different workloads, with different performance, power, and cost requirements to get the job done. Historically, researchers and application scientists have flocked to GPUs as their hardware of choice for machine learning workloads. Compared to its closest hardware competitor, the CPU, a GPU exhibits a higher aptitude for parallel computations, which are extremely prevalent in machine learning. This advantage is especially pronounced when a cluster of GPUs is used to create a general purpose computing device, referred to as a GPGPU. With a software infrastructure surrounding them in NVIDIAâ€™s CUDA platform, GPGPUs make up ground in flexibility and ease of use, areas in which a CPU would typically outperform a standalone GPU. In more recent research, however, FPGAs have become an increasingly popular option for accelerating machine learning workloads, due to their low power consumption, customizability, and ability to exploit pipeline parallelism. As opposed to the data parallelism that GPUs excel at, computing the same operation on many pieces of data at once, pipeline parallelism involves performing and forwarding output from multiple different operations at once. This research seeks to identify and define a new potential optimization to machine learning workloads in the form of an FPGA-based accelerator.
