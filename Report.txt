Machine learning is an ever-expanding field, with wide-reaching applications in areas such as economics, biology, and medicine, just to name a few. With such a wide variety of use cases comes a wide range of different workloads, with different performance, power, and cost requirements to get the job done. Historically, researchers and application scientists have flocked to GPUs as their hardware of choice for machine learning workloads. Compared to its closest hardware competitor, the CPU, a GPU exhibits a higher aptitude for parallel computations, which are extremely prevalent in machine learning. This advantage is especially pronounced when a cluster of GPUs is used to create a general purpose computing device, referred to as a GPGPU. With a software infrastructure surrounding them in NVIDIA’s CUDA platform, GPGPUs make up ground in flexibility and ease of use, areas in which a CPU would typically outperform a standalone GPU. In more recent research, however, FPGAs have become an increasingly popular option for accelerating machine learning workloads, due to their low power consumption, customizability, and ability to exploit pipeline parallelism. As opposed to the data parallelism that GPUs excel at, computing the same operation on many pieces of data at once, pipeline parallelism involves performing and forwarding output from multiple different operations at once. This research seeks to identify and define a new potential optimization to machine learning workloads in the form of an FPGA-based accelerator.
There has been extensive innovation in the field of FPGA-based machine learning in recent years. Researchers are continuously developing new ways to use FPGAs to solve a variety of problems. Some examples include optimizing for specific use cases, creating a model more general use, broadening to large scale use, and partnering with complementary technologies. One study that targeted a specific use case was conducted in 2017 by researchers at ETH Zurich. Kara et al. focused on Stochastic Gradient Descent (SGD), an algorithm that is commonly used in training machine learning models, and programmed an FPGA to perform this function on datasets of varying precision. They found that lowering the precision of the input data could speed up the training process anywhere from 2-11x depending on the workload. Performing an analysis similar to this one, in which an FPGA is used as a tool to assess the viability of a tradeoff in the machine learning model, would be a reasonable scope for a new FPGA project. A more ambitious problem is tackled in the instance of DeepBurning. Wang, et al. provide a sort of meta-solution for using FPGAs to accelerate machine learning workloads, in which deep learning is implemented to program the FPGA itself. Another study, titled DianNao, applied FPGAs to large-scale workloads and found that their implementation outperformed a general purpose processor solution by 2 orders of magnitude. These two papers lay the groundwork for more possible definitions of success for a project, where FPGAs are either used in a completely new way or are used to improve an existing workload by a significant amount. One final point to touch on when considering research with FPGAs is that of a heterogeneous solution. In a 2015 paper, researchers at George Mason University outline a methodology to identify CPU-intensive workloads that can be offloaded to an FPGA, and create a solution that implements both pieces of hardware. They measured an overall speedup of close to 3x when offloading certain computations to an FPGA. This outline demonstrates yet another successful way to research with FPGAs - implementing a heterogeneous solution that can be directly compared against a general purpose processing solution running on the same workload. 
	The efforts described above pave multiple possible paths for a future successful FPGA research project. This new use for FPGA in the field of machine learning should satisfy at least one of the following requirements:

Use FPGA as a configurable tool to test the effects of a change in a specific parameter
Develop a methodology that makes using an FPGA more versatile and broadly impactful
Apply an FPGA solution to a specific workload and achieve a speedup
Implement a heterogeneous solution that pairs FPGA with an existing solution to achieve a speedup

In addition, any project intending to meet goals (1) or (2) should be tested on multiple different types of training data, as well as multiple datasets of the same type. Any project planning to accomplish (3) or (4) should target an average of at least 1.4x overall speedup. These are modest goals based on the results of prior work. Solutions aiming to be generally applied should be proven to work with different types of data, a trait demonstrable with publicly available training sets. Furthermore, different datasets of the same type should be used to determine that the solution works for a type of data, as opposed to a particular dataset. Some popular choices include mnist and gisette, two sets of images of handwritten digits, text data such as Amazon reviews or Twitter posts, or audio like Free Music Archive. The target speedup number represents the approximate annual rate needed to keep up with Moore’s law of doubling a machine’s capability every 2 years. Some prior work shatters this number, recording orders of magnitude of performance improvement over the comparable existing solution. 

	In summary, existing publications establish several different types of blueprints for using FPGAs to accelerate machine learning models. A new FPGA could be used to test a potential optimization, improve performance a specific workload, complement an existing general purpose solution, or even revolutionize as a whole the way that researchers and application engineers work with FPGAs. FPGAs are a desirable hardware option because they are fast, low power, and configurable for both custom and general use. The main advantage that a current GPGPU solution would have over an FPGA is the software infrastructure, allowing for easier implementation and quicker turnaround time. Most current FPGA implementations target specific algorithms or functions in the machine learning process. But, as more and more work is done using FPGAs, a similar environment could emerge that rivals the current standard. There is ever growing demand for faster and denser machine learning hardware for countless real-world applications, and FPGAs are a great candidate for propelling innovation in the field as a whole.
